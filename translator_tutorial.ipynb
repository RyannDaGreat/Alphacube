{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bbcef5-4358-46b6-9c19-155c9bace134",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98261340-20d7-48df-bbab-d9ca3119ce6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297479ca-2c18-4cb9-aab9-10ac37619b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import icecream\n",
    "sys.path.append('./translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1930b7-b2eb-462f-a765-49bab7851885",
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QDs4Im9WTQoy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import rp\n",
    "from translator.trainer import MUNIT_Trainer as Trainer\n",
    "from translator.data import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb7ce7-1dd5-4cb4-8d43-2ef4acb13d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa85a3-b966-4ce5-8c1f-90e59f7e6b72",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be09caf-f560-481e-82f0-881dee44f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c206b5-ac5c-43af-8f62-800da87b35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c90e85-0b30-463b-ab23-f465fc5b6678",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8c826-a8c7-449d-ab9c-253907611853",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file       = './translator/configs/alphablock_without_ssim_256.yaml'\n",
    "image_folder_path = './datasets/alphacube/scenes/'\n",
    "# image_folder_path = './datasets/alphacube/anim_2/'\n",
    "# image_folder_path = './datasets/alphacube/anim_1/'\n",
    "image_folder_path = '/mnt/Noman/Ubuntu/CleanCode/Datasets/diff_rendering/alphabetcube_L/SyntheticData/Anim3/Renderings'\n",
    "checkpoint_folder = './translator/trained_models/outputs/alphablock_without_ssim_256/checkpoints'\n",
    "# checkpoint_folder = './translator/trained_models/outputs/alphablock_without_ssim_256/checkpoints/old_checkpoints/v0.0.7'\n",
    "# checkpoint_folder = './translator/save'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d7724-789a-498d-9e88-cc027a262687",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = rp.load_yaml_file(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd994fdf-d690-4dde-99aa-dc03da8cd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer=Trainer(config, trainable=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c516e9-ffba-4de4-b039-68a7eb5a1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.resume(checkpoint_folder, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d71943-7f6d-47d9-8711-669e7c2a3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image(rp.tiled_images(rp.as_numpy_images(trainer.texture_pack())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e207e22-4cd7-48b3-be2a-378b52805172",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TODO: Make the Trainer save the neural texture once, so during inference we don't need to run it over and over again (it's redundant to do that seeing as the texture never changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dafbc9-4b72-40b7-8a6f-0ab673649c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = {}\n",
    "aug[\"new_size_min\"] = config[\"new_size_min_a\"]\n",
    "aug[\"new_size_max\"] = config[\"new_size_max_a\"]\n",
    "aug[\"output_size\" ] = (-1,-1) #Meaningless when skip_crop = True\n",
    "# aug[\"output_size\" ] = (320,320) #Meaningless when skip_crop = True\n",
    "image_folder = ImageFolder(root=image_folder_path, precise=True, augmentation=aug)\n",
    "image_folder.skip_crop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d859811e-840c-451f-b92e-13afa7c12aae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9097fa8-e11e-4f13-8489-33a3d779ae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "o=rp.random_element(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5be34ae-f035-4a8b-b734-c8d363e7867a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, height, width = o.shape\n",
    "icecream.ic(height,width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7b9319-a9b0-4e01-8948-a21d1e28182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.display_image(rp.as_numpy_image(o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001f9d49-5254-4b9d-bd4b-d9860acb8c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h=o[None].to(device)\n",
    "i=trainer.sample_a2b(h)\n",
    "\n",
    "\n",
    "rp.display_image(rp.as_numpy_image(h[0]))\n",
    "rp.display_image(rp.as_numpy_image(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a04f55-2448-4b93-8009-8878a72b66c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=trainer.sample(h,h)[:7]\n",
    "for x in i:\n",
    "    rp.display_image(rp.as_numpy_image(x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319ec8f-d46b-4ce8-961c-6b672285267b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d469bda-215d-43e6-8eac-4194afb81681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(image):\n",
    "    #Input image is a UV-L Scene\n",
    "    assert rp.is_image(image)\n",
    "    image = rp.as_rgb_image  (image)\n",
    "    image = rp.as_float_image(image)\n",
    "    \n",
    "    image = rp.as_torch_image(image)[None] #BCHW\n",
    "    image = image.to(device)\n",
    "    \n",
    "    output = trainer.sample_a2b(image)\n",
    "    output = output[0]\n",
    "    output = rp.as_numpy_image(output)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506427c2-7f09-4c85-9846-054ac333224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = rp.load_images(image_folder_path, show_progress=True)\n",
    "clear_output()\n",
    "\n",
    "images = [rp.cv_resize_image(image, (height, width), 'nearest') for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc203b5-6f3c-4cfe-9f05-ef66a92f1554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display_eta = rp.eta(len(images))\n",
    "translations = []\n",
    "for index,image in enumerate(images):\n",
    "    display_eta(index)\n",
    "    translations.append(translate(image))\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d72e95-099b-4275-b7ab-4dc74bf979e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please be patient, this step can take a long time to complete (up to 5 minutes)\n",
    "#This is because it's extremely inefficient lol. All images in this animation are being converted into base-64 in html\n",
    "# rp.display_image_slideshow(translations[::5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634462cd-d43d-436a-815f-b03a434a12f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = 'untracked/animation.mp4'\n",
    "rp.save_video(translations,'untracked/animation.mp4')\n",
    "clear_output()\n",
    "# translations=[rp.as_byte_image(x) for x in translations]\n",
    "# translations=rp.as_numpy_array(translations)\n",
    "# write_mp4(video_path, translations)\n",
    "\n",
    "from IPython.display import Video\n",
    "icecream.ic(video_path)\n",
    "Video(video_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
