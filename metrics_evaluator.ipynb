{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14cffd20-9ff9-4a37-bb58-68405c992577",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f877c94c-2614-498b-a3ce-890f21bd5a8c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4961521f-fc83-4bd7-84af-3f592a2d32b3",
   "metadata": {
    "scene__JustVid": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import icecream\n",
    "import torch\n",
    "import json\n",
    "import rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260c964-b212-450b-88cf-f637710d73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp.pip_import('lpips') # https://pypi.org/project/lpips/\n",
    "import lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bd031-386a-40fb-81c1-3c351cf63377",
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "QDs4Im9WTQoy",
    "scene__JustVid": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "sys.path.append('./translator')\n",
    "from translator.easy_translator import EasyTranslator\n",
    "from translator.pytorch_msssim import numpy_msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2d2f70-2c84-4e60-8e3c-646c86000ee9",
   "metadata": {
    "scene__JustVid": true,
    "tags": [
     "ActiveScene"
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cddbc17-1445-4ebe-9c96-032b2c62ffc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Other Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79da43d9-06c0-4d4f-b345-08a5fe94e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# devuce = 'cpu'\n",
    "torch.cuda.set_device(0) #Choose a free GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c687f-43b5-47a9-82f3-bbd8030d15b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064a22fd-663e-4e44-a53b-71b9d049e5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8021be-2e5a-45df-a86e-19b6673f89c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls untracked | grep TEST_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b519ab63-8101-4098-aae9-dfb171abbb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  NOTE: Generate these variations with translator_tester.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcba1c10-e1a9-4e22-af27-4494476f24c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VARIATION_NAME='TEST_OUT__alphabet_five_base__pure_munit'\n",
    "VARIATION_NAME='TEST_OUT__alphabet_three_base__only_texture'\n",
    "VARIATION_NAME='TEST_OUT__alphabet_three_base__just_tex_reality__run0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fad740-a714-4fdf-9414-36afd46546d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_root='/raid/ryan/CleanCode/Datasets/diff_rendering/alphabet_three/test'\n",
    "translation_folder='./untracked/'+VARIATION_NAME\n",
    "translation_filetype='png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8dbfb-da14-4ed9-8f3f-ad25867d5385",
   "metadata": {},
   "outputs": [],
   "source": [
    "photo_folder=rp.path_join(test_root,'halved_photos')\n",
    "photo_folder=rp.path_join(test_root,'halved_photos')\n",
    "matches=json.loads(rp.text_file_to_string(rp.path_join(test_root,\"matches.json\")))\n",
    "trans_dims=rp.get_image_file_dimensions(rp.random_element(rp.get_all_files(translation_folder)))\n",
    "icecream.ic(trans_dims);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20265a97-7473-4b1e-834b-ba9d1835a05b",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382a6a49-ad10-4ea9-adf8-9d5005155d18",
   "metadata": {},
   "source": [
    "####  REMEMBER: Lower LPIPS is better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a70cb-79ae-465e-a951-e4163643d7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_alex = lpips.LPIPS(net='alex').to(device)\n",
    "def perceptual_loss(photo, trans):\n",
    "    #Lower is better!\n",
    "    \n",
    "    photo=rp.cv_resize_image(photo,rp.get_image_dimensions(trans))\n",
    "    \n",
    "    img1=photo\n",
    "    img2=trans\n",
    "    \n",
    "    img1 = rp.as_float_image(rp.as_rgb_image(img1))\n",
    "    img2 = rp.as_float_image(rp.as_rgb_image(img2))\n",
    "    \n",
    "    assert img1.shape==img2.shape\n",
    "    \n",
    "    img1 = img1*2-1 # [0,1] -> [-1,1]\n",
    "    img2 = img2*2-1 # [0,1] -> [-1,1]\n",
    "    \n",
    "    img1 = rp.as_torch_image(img1)[None].to(device)\n",
    "    img2 = rp.as_torch_image(img2)[None].to(device)\n",
    "    \n",
    "    return float(loss_fn_alex(img1, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4e67f0-2da3-4ef7-95db-c541c5a8288e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_translation(translation_name):\n",
    "    translation_file=rp.with_file_extension(translation_name,translation_filetype)\n",
    "    trans=rp.load_image(rp.path_join(translation_folder,translation_file))\n",
    "    trans=rp.as_float_image(trans)\n",
    "    trans=rp.as_rgb_image(trans)\n",
    "    return trans\n",
    "def load_photo(photo_filename):\n",
    "    photo_filename=rp.get_file_name(photo_filename)\n",
    "    photo=rp.load_image(rp.path_join(photo_folder,photo_filename))\n",
    "    photo=rp.cv_resize_image(photo,trans_dims)\n",
    "    photo=rp.as_float_image(photo)\n",
    "    photo=rp.as_rgb_image(photo)\n",
    "    return photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c3039-5ea7-4f6a-be48-33ef4da327e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lpips={}\n",
    "scores_l2={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c98d2b-4f63-43fa-8a78-3da80aead37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wipe_line='\\r'+' '*100+'\\r'\n",
    "for photo_filename in matches:\n",
    "    print(wipe_line+photo_filename)\n",
    "    photo=load_photo(photo_filename)\n",
    "    translation_names=matches[photo_filename]\n",
    "    display_eta=rp.eta(len(translation_names))\n",
    "    for i,translation_name in enumerate(translation_names):\n",
    "        display_eta(i)\n",
    "        trans=load_translation(translation_name)\n",
    "        if translation_name not in scores_lpips:\n",
    "            scores_lpips[translation_name]=perceptual_loss(photo,trans)\n",
    "        if translation_name not in scores_l2:\n",
    "            scores_l2[translation_name]=((photo-trans)**2).mean()\n",
    "print(wipe_line+'DONE!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139e9b35-f3c9-4426-9fe6-f61decd34675",
   "metadata": {},
   "outputs": [],
   "source": [
    "icecream.ic(\n",
    "    min(scores_lpips.values()),\n",
    "    max(scores_lpips.values()),\n",
    "    len(scores_lpips),\n",
    "    min(scores_l2.values()),\n",
    "    max(scores_l2.values()),\n",
    "    len(scores_l2),\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e228da56-61a2-4d65-8a09-5d1dd73a3a15",
   "metadata": {},
   "source": [
    "NOTES:\n",
    "Unsuprisingly, L2 fails to find the correct permutation more often than LPIPS does.\n",
    "That being said, even when searching for the best L2, its corresponding LPIPS score is still .1x -- far better than any of the other translation methods.\n",
    "Let's do a flex here: let's force my method to stick to a single permutation for all samples, but let the other algorithms do a different permutation each. In addition, let's compare histograms of the distributions of the scores (best scores - meaning 14 datapoints per). IN FACT: The minimum of one method is LARGER than the average of another! (((I BET ITS CAUSE OF THE TABLE. MASK THE TABLE!)))\n",
    "\n",
    "## TODO: Compare to reconstructions! Mask out the cubes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f8f1a-4494-41a0-982a-d00b93248166",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_line_graphs=False\n",
    "\n",
    "print(\"Displaying individual, uncoordinated best matchings\")\n",
    "\n",
    "def get_best_translation_name(photo_file,scores=scores_lpips):\n",
    "    subdict={trans_name:scores[trans_name] for trans_name in matches[photo_file]}\n",
    "    return sorted(subdict,key=lambda trans_name:scores[trans_name])[0] #0 for the first best, 1 for the second best, etc\n",
    "\n",
    "for photo_file in matches:\n",
    "    best_trans_name=get_best_translation_name(photo_file)\n",
    "    \n",
    "    score_lpips=scores_lpips[best_trans_name]\n",
    "    score_l2   =scores_l2[best_trans_name]\n",
    "    \n",
    "    photo = load_photo(photo_file)\n",
    "    trans = load_translation(best_trans_name)\n",
    "    \n",
    "    info_image = rp.labeled_image(\n",
    "        rp.horizontally_concatenated_images(\n",
    "            photo,\n",
    "            trans,\n",
    "            abs(photo-trans).mean(2),\n",
    "        ),\n",
    "        rp.get_file_name(photo_file)+' : '+best_trans_name + ',  LPIPS = %.3f,  L2 = %.4f'%(score_lpips,score_l2),\n",
    "        size=20,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(photo_file,best_trans_name,score_lpips)\n",
    "    rp.display_image(info_image)\n",
    "    if display_line_graphs:\n",
    "        rp.line_graph_via_bokeh(\n",
    "            {\n",
    "                'LPIPS':sorted([scores_lpips[x] for x in matches[photo_file]]),\n",
    "                'L2'   :sorted([scores_l2   [x] for x in matches[photo_file]]),\n",
    "            },\n",
    "            title='Score Distribution',\n",
    "            logy=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e45d6-b70f-46c4-871d-d328c14d35ad",
   "metadata": {},
   "source": [
    "# Histogram TEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40035bb4-45fd-4995-86f0-6deafbdbafc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import numpy as np\n",
    "# from bokeh.io import show, output_notebook\n",
    "# from bokeh.plotting import figure\n",
    "# output_notebook()\n",
    "\n",
    "# data = np.random.normal(0, 0.5, 1000)\n",
    "# hist, edges = np.histogram(data, density=True, bins=10)\n",
    "\n",
    "# p = figure()\n",
    "# p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"white\")\n",
    "\n",
    "# show(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0587a9e-a3ec-44fa-9269-b0d871cde74c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
